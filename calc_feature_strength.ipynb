{
 "metadata": {
  "name": "",
  "signature": "sha256:879cf9bb184cb52a77f7004c17191d5c2e6b1c859fbf6ebebf36050cb4814c07"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u0443\u0441\u043a\u0430 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv('c:/data/pool.tsv', delimiter='\\t', header=None )\n",
      "\n",
      "data_learn = data[(data[1] != -1) & (data[0] % 33 < 22)]\n",
      "learn_features = data_learn.drop([0, 1, 2], axis=1)\n",
      "learn_target = data_learn[1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u0444\u0430\u043a\u0442\u043e\u0440\u0430 \u043d\u0430 \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u043e\u0442 \u043d\u0435\u0433\u043e\n",
      "\n",
      "from sklearn import metrics, cross_validation, linear_model\n",
      "from datetime import datetime\n",
      "from scipy import stats\n",
      "import numpy as np\n",
      "\n",
      "clf = linear_model.RidgeClassifier()\n",
      "kf_total = cross_validation.KFold(len(learn_features), n_folds=10, shuffle=True, random_state=4)\n",
      "\n",
      "def calc_model(fset):\n",
      "    start_time = datetime.now()\n",
      "    ans = cross_validation.cross_val_score(clf, learn_features[fset], learn_target, scoring='roc_auc', cv=kf_total, n_jobs=3)\n",
      "    print datetime.now() - start_time\n",
      "    return ans\n",
      "\n",
      "def compare_quality(q1, q2):\n",
      "    return np.mean(q2) - np.mean(q1), stats.ttest_rel(q1, q2)[1]\n",
      "\n",
      "base_fset = range(3,103)\n",
      "base_q = calc_model(base_fset)\n",
      "\n",
      "# 110 \u0444\u0430\u043a\u0442\u043e\u0440 - \u0437\u043d\u0430\u0447\u0438\u043c\u043e \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 (p-value < 0.01)\n",
      "q = calc_model(base_fset + [110])\n",
      "print compare_quality(base_q, q)\n",
      "    \n",
      "# 103 \u0444\u0430\u043a\u0442\u043e\u0440 - \u043d\u0435 \u0437\u043d\u0430\u0447\u0438\u043c\u043e \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\n",
      "q = calc_model(base_fset + [103])\n",
      "print compare_quality(base_q, q)\n",
      "\n",
      "# 189 \u0444\u0430\u043a\u0442\u043e\u0440 - \u0437\u043d\u0430\u0447\u0438\u043c\u043e \u0443\u0445\u0443\u0434\u0448\u0430\u0435\u0442 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\n",
      "q = calc_model(base_fset + [189])\n",
      "print compare_quality(base_q, q)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0:00:02.900000\n",
        "0:00:02.225000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.0030602512988182617, 0.0029885880453920355)\n",
        "0:00:01.760000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.00088123113985494328, 0.38288813169480362)\n",
        "0:00:01.729000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(-0.00021978486341567294, 0.0095585002388153973)\n"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}